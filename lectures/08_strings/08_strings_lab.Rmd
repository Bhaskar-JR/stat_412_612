---
title: "Strings Lab"
date: "`r Sys.Date()`"
author: "David Gerard"
output: pdf_document
urlcolor: "blue"
params: 
  solutions: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = params$solutions, eval = params$solutions)
```

# Learning Objectives

- Practice `stringr`, `dplyr`, and `ggplot2`.

# Exercise 1: Scrabble Words

For this exercise, we are using the 
[Collins Scrabble Words](https://en.wikipedia.org/wiki/Collins_Scrabble_Words),
which is most commonly used outside of the United States. The dictionary most 
often used in the United States is the
[Tournament Word List](https://en.wikipedia.org/wiki/Official_Tournament_and_Club_Word_List).

1. Load the 2015 list of Collins Scrabble Words into R from
   <https://dcgerard.github.io/stat_412_612/data/words.txt> (note: "NA" is an
   official Scrabble word).

    ```{r, eval = TRUE, message=FALSE}
    library(tidyverse)
    ```
    
    ```{r}
    worddf <- read_csv("../../data/words.txt", na = character())
    wordvec <- worddf$word
    ```

2. There is a mnemonic rule in English: "i before e except after c". This states
   that if you are unsure of the sequence of "ei" or "ie", then you should 
   choose "ie" unless this sequence follows "c". Use regex and stringr to 
   determine how many scrabble words violate this rule and how many scrabble
   words satisfy this rule. Hint: check for "EITHER" in your word list.
   
    ```{r}
    is_cie <- str_detect(wordvec, "CIE")
    is_ei  <- str_detect(wordvec, "[^C]EI") | str_detect(wordvec, "^EI")
    sum(is_cie | is_ei) ## number of violations
    
    is_cei <- str_detect(wordvec, "CEI")
    is_ie  <- str_detect(wordvec, "[^C]IE") | str_detect(wordvec, "^IE")
    sum(is_cei | is_ie) ## number of satisfications
    
    ## So about 19% of candidate words violate this rule
    sum(is_cie | is_ei) / sum(is_cei | is_ie | is_cie | is_ei)
    ```
    
3. Suppose you switch the "E" and the "I" in any word that contains an "EI" or 
   "IE" pair. How many of these resulting strings still valid scrabble words?
   What are the shortest and longest strings that are still words?
   
    ```{r}
    is_eiwords  <- str_detect(wordvec, "EI")
    switchwords <- str_replace(wordvec[is_eiwords], "EI", "IE")
    stillword <- switchwords %in% wordvec
    
    subswitch <- switchwords[stillword]
    
    pairdf <- tibble(ie = subswitch, 
                     ei = str_replace(subswitch, "IE", "EI"),
                     length = str_length(subswitch))
    
    pairdf %>%
      arrange(length) %>%
      head()
    
    pairdf %>%
      arrange(desc(length)) %>%
      head()
    ```

4. Challenge (you can skip this one if you want).
   A *palindrome* is a word that is the same read backword as forward. 
   For example *racecar* and *madam*. How many palindromes are there? What is
   the longest palindrome? You might need a `for` loop here.
   
    ```{r}
    strmat <- str_split(wordvec, pattern = "", simplify = TRUE)
    palvec <- apply(strmat[, ncol(strmat):1], 1, str_c, collapse = "")
    whichpal <- palvec == wordvec
    sum(whichpal)
    
    tibble(word = wordvec[whichpal]) %>%
      mutate(length = str_length(word)) %>%
      arrange(desc(length))
    ```
   
   
   

# Exercise 2: Jane Austen

For this exercise, we will consider the works of 
[Jane Austen](https://en.wikipedia.org/wiki/Jane_Austen) as stored in the
janeaustenr package.

```{r, echo = TRUE}
library(janeaustenr)
bookdf <- austen_books()
```

`bookdf` (which we created above) is a data frame that contains a line of 
text and the book from which that line belongs.

1. Populate `bookdf` with line numbers (so at the start of each book, the line
   number begins at 1).

    ```{r}
    bookdf %>%
      group_by(book) %>%
      mutate(line_number = row_number()) %>%
      ungroup() ->
      bookdf
    ```

2. Add a column to `bookdf` called `new_chapter` that is `TRUE` if the line 
   begins a new chapter and `FALSE` otherwise.

    ```{r}
    bookdf %>%
      mutate(new_chapter = str_detect(text, "^CHAPTER")) ->
      bookdf
    ```

3. Read about the `cumsum()` function. Try it out on the following vector:
    ```{r, echo = TRUE}
    c(FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE)
    ```
    
    What do you think `cumsum()` does when evaluated with a logical vector?

4. Use the `cumsum()` function (as well as other functions)
   to find the chapter number of each line of text. Add this as a new column 
   to `bookdf` called `chapter`.
   
    ```{r}
    bookdf %>%
      group_by() %>%
      mutate(chapter = cumsum(new_chapter)) %>%
      ungroup() ->
      bookdf
    ```
    
5. Apply this code to get one word per row in the data frame `janedf`:

    ```{r, echo = TRUE}
    library(tidytext)
    bookdf %>%
      unnest_tokens(word, text) ->
      janedf
    ```
    
6. Use stringr and regular expressions to create shortened titles for the books
   that contain just the first characters of each word. For example, 
   `"Sense & Sensibility"` should change to `"S&S"` while `"Emma"` should 
   change to just `"E"`. Add these shortened titles to the `janedf` data frame.
   
    Hints: I used `str_replace_all()` for this question.
    Try making the regex changes on this data frame then use joining.

    ```{r, echo = TRUE}
    book_title <- tibble(book = levels(janedf$book))
    ```
    
    ```{r}
    book_title %>%
      mutate(short_title = str_replace_all(book, pattern = "[a-z ]", "")) ->
      book_title
    
    janedf %>%
      left_join(book_title, by = "book") ->
      janedf
    ```
   
7. Is there an association between word length and book? First, calculate the
   proportion of words of each length for each book.
   
    ```{r}
    janedf %>%
      mutate(length = str_length(word)) %>%
      group_by(book, length) %>%
      count() %>%
      ungroup() %>%
      group_by(book) %>%
      mutate(prop = n / sum(n)) ->
      word_count_df
    ```
    
     Now use `geom_line()` to plot the word length against proportion of words,
     color coding by book.
   
    ```{r}
    ## The distribution is almost identical.
    ggplot(word_count_df, aes(x = length, y = prop, color = book)) +
      geom_line() +
      theme_bw() +
      xlab("Book") +
      ylab("Length")
    ```

8. From the `bookdf` data frame, create a data frame with two columns, `book`
   and `text`. There should be only six rows, and each element in `text` should
   contain the entire text from the book in `book`.
   
    ```{r}
    bookdf %>%
      group_by(book) %>%
      summarize(text = str_c(text, collapse = " ")) ->
      alldf
    ```
   
9. Create a function that will take as input a string and return another string
   where the name of any Bennet sister mentioned is preceded with "mecha". The
   Bennet sisters are Elizabeth (Eliza or Lizzy), Mary, Kitty (Catherine), 
   Lydia, and Jane.
   
    For example, in my implementation, `mechabennet()`, I have the following 
    outputs:
   
    ```{r, eval = TRUE}
    mechabennet <- function(x) {
      str_replace_all(x, "(Elizabeth|Eliza|Lizzy|Mary|Kitty|Catherine|Lydia|Jane)", 
                      "mecha-\\1")
    }
    ```

    ```{r, eval = TRUE, echo = TRUE}
    text <- "Elizabeth passed quietly out of the room, Jane and Kitty followed"
    mechabennet(text)
    ```
   




